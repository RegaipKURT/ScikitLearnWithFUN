{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd374c64",
   "metadata": {},
   "source": [
    "# üìù Exercise M7.01\n",
    "\n",
    "This notebook aims at building baseline classifiers, which we'll use to\n",
    "compare our predictive model. Besides, we will check the differences with\n",
    "the baselines that we saw in regression.\n",
    "\n",
    "We will use the adult census dataset, using only the numerical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cba694cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "adult_census = pd.read_csv(\"../datasets/adult-census-numeric-all.csv\")\n",
    "data, target = adult_census.drop(columns=\"class\"), adult_census[\"class\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd12e81",
   "metadata": {},
   "source": [
    "First, define a `ShuffleSplit` cross-validation strategy taking half of the\n",
    "sample as a testing at each round."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ccf877ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here.\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "cv = ShuffleSplit(n_splits=30, test_size=0.5, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49dbbbe5",
   "metadata": {},
   "source": [
    "Next, create a machine learning pipeline composed of a transformer to\n",
    "standardize the data followed by a logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ffd2be1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here.\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "pipeline = make_pipeline(StandardScaler(), LogisticRegression())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6188b6d8",
   "metadata": {},
   "source": [
    "Get the test score by using the model, the data, and the cross-validation\n",
    "strategy that you defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b5f5d525",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Test Errors\n",
      " 0    0.813715\n",
      "1    0.810235\n",
      "2    0.807125\n",
      "3    0.812244\n",
      "4    0.810811\n",
      "5    0.816544\n",
      "6    0.811835\n",
      "7    0.815111\n",
      "8    0.821048\n",
      "9    0.822891\n",
      "Name: 0, dtype: float64 \n",
      "Mean Test Accuracy:  0.8141559387618754\n"
     ]
    }
   ],
   "source": [
    "# Write your code here.\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "cv_scores = cross_validate(pipeline, data, target, cv=10, n_jobs=-1,\n",
    "                           scoring=\"accuracy\")\n",
    "\n",
    "print(\"CV Test Errors\\n\", pd.DataFrame(cv_scores[\"test_score\"])[0],\n",
    "      \"\\nMean Test Accuracy: \", cv_scores[\"test_score\"].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef6dfe5",
   "metadata": {},
   "source": [
    "Using the `sklearn.model_selection.permutation_test_score` function,\n",
    "check the chance level of the previous model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6264287a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    -0.760868\n",
       "1    -0.761014\n",
       "2    -0.760698\n",
       "3    -0.761286\n",
       "4    -0.761294\n",
       "5    -0.761005\n",
       "6    -0.761252\n",
       "7    -0.760735\n",
       "8    -0.761005\n",
       "9    -0.760650\n",
       "10   -0.760726\n",
       "11   -0.761267\n",
       "12   -0.760817\n",
       "13   -0.761558\n",
       "14   -0.760927\n",
       "15   -0.760946\n",
       "16   -0.760821\n",
       "17   -0.761066\n",
       "18   -0.761154\n",
       "19   -0.760215\n",
       "20   -0.760631\n",
       "21   -0.761160\n",
       "22   -0.760751\n",
       "23   -0.760694\n",
       "24   -0.761210\n",
       "25   -0.760576\n",
       "26   -0.760792\n",
       "27   -0.760485\n",
       "28   -0.761106\n",
       "29   -0.760378\n",
       "Name: Permuted error, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write your code here.\n",
    "from sklearn.model_selection import permutation_test_score\n",
    "\n",
    "regressor = LogisticRegression()\n",
    "score, permutation_score, pvalue = permutation_test_score(\n",
    "    regressor, data, target, cv=cv, scoring=\"accuracy\",\n",
    "    n_jobs=-1, n_permutations=30)\n",
    "errors_permutation = pd.Series(-permutation_score, name=\"Permuted error\")\n",
    "errors_permutation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b69db9",
   "metadata": {},
   "source": [
    "Finally, compute the test score of a dummy classifier which would predict\n",
    "the most frequent class from the training set. You can look at the\n",
    "`sklearn.dummy.DummyClassifier` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e1a7f316",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here.\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "dummy = DummyClassifier(strategy=\"most_frequent\")\n",
    "result_dummy = cross_validate(dummy, data, target, cv=cv, n_jobs=2)\n",
    "test_score_dummy = pd.Series(result_dummy[\"test_score\"], name=\"Dummy score\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122484ba",
   "metadata": {},
   "source": [
    "Now that we collected the results from the baselines and the model, plot\n",
    "the distributions of the different test scores."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbeec3dc",
   "metadata": {},
   "source": [
    "We concatenate the different test score in the same pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1326fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here.\n",
    "final_test_scores = pd.concat(\n",
    "    [test_score_classifier, test_score_permutation, test_score_dummy],\n",
    "    axis=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1805189",
   "metadata": {},
   "source": [
    "Next, plot the distributions of the test scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfbaf9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d79f782",
   "metadata": {},
   "source": [
    "Change the strategy of the dummy classifier to `stratified`, compute the\n",
    "results and plot the distribution together with the other results. Explain\n",
    "why the results get worse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26b87df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "nbreset": "https://github.com/INRIA/scikit-learn-mooc/raw/master/notebooks/cross_validation_ex_02.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
