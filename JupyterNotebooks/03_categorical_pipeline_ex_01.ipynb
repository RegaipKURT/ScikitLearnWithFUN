{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e820bfc1",
   "metadata": {},
   "source": [
    "# üìù Exercise M1.04\n",
    "\n",
    "The goal of this exercise is to evaluate the impact of using an arbitrary\n",
    "integer encoding for categorical variables along with a linear\n",
    "classification model such as Logistic Regression.\n",
    "\n",
    "To do so, let's try to use `OrdinalEncoder` to preprocess the categorical\n",
    "variables. This preprocessor is assembled in a pipeline with\n",
    "`LogisticRegression`. The statistical performance of the pipeline can be\n",
    "evaluated by cross-validation and then compared to the score obtained when\n",
    "using `OneHotEncoder` or to some other baseline score.\n",
    "\n",
    "First, we load the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a406b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "adult_census = pd.read_csv(\"../datasets/adult-census.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0fb1fb7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_name = \"class\"\n",
    "target = adult_census[target_name]\n",
    "data = adult_census.drop(columns=[target_name, \"education-num\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1bca09d",
   "metadata": {},
   "source": [
    "In the previous notebook, we used `sklearn.compose.make_column_selector` to\n",
    "automatically select columns with a specific data type (also called `dtype`).\n",
    "Here, we will use this selector to get only the columns containing strings\n",
    "(column with `object` dtype) that correspond to categorical features in our\n",
    "dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d084d4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import make_column_selector as selector\n",
    "\n",
    "categorical_columns_selector = selector(dtype_include=object)\n",
    "categorical_columns = categorical_columns_selector(data)\n",
    "data_categorical = data[categorical_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac0cca7f",
   "metadata": {},
   "source": [
    "We filter our dataset that it contains only categorical features.\n",
    "Define a scikit-learn pipeline composed of an `OrdinalEncoder` and a\n",
    "`LogisticRegression` classifier.\n",
    "\n",
    "Because `OrdinalEncoder` can raise errors if it sees an unknown category at\n",
    "prediction time, you can set the `handle_unknown=\"use_encoded_value\"` and\n",
    "`unknown_value` parameters. You can refer to the\n",
    "[scikit-learn documentation](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OrdinalEncoder.html)\n",
    "for more details regarding these parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "101cd0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "pipeline = make_pipeline(OrdinalEncoder(handle_unknown=\"use_encoded_value\",\n",
    "                                       unknown_value=-1), \n",
    "                         LogisticRegression(max_iter=500))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8caf6bc3",
   "metadata": {},
   "source": [
    "Your model is now defined. Evaluate it using a cross-validation using\n",
    "`sklearn.model_selection.cross_validate`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e36919d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean cross-validation accuracy is: 0.755 +/- 0.002\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "cross_val = cross_validate(pipeline, data_categorical, target)\n",
    "scores = cross_val[\"test_score\"]\n",
    "print(\"The mean cross-validation accuracy is: \"\n",
    "      f\"{scores.mean():.3f} +/- {scores.std():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1120a584",
   "metadata": {},
   "source": [
    "Now, we would like to compare the statistical performance of our previous\n",
    "model with a new model where instead of using an `OrdinalEncoder`, we will\n",
    "use a `OneHotEncoder`. Repeat the model evaluation using cross-validation.\n",
    "Compare the score of both models and conclude on the impact of choosing a\n",
    "specific encoding strategy when using a linear model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb7b6bdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:696: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 687, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 397, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/utils/metaestimators.py\", line 120, in <lambda>\n",
      "    out = lambda *args, **kwargs: self.fn(obj, *args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/pipeline.py\", line 618, in score\n",
      "    Xt = transform.transform(Xt)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/preprocessing/_encoders.py\", line 471, in transform\n",
      "    X_int, X_mask = self._transform(X, handle_unknown=self.handle_unknown,\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/preprocessing/_encoders.py\", line 136, in _transform\n",
      "    raise ValueError(msg)\n",
      "ValueError: Found unknown categories [' Holand-Netherlands'] in column 7 during transform\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean cross-validation accuracy is: nan +/- nan\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "pipeline = make_pipeline(OneHotEncoder(), LogisticRegression(max_iter=500))\n",
    "\n",
    "cross_val = cross_validate(pipeline, data_categorical, target)\n",
    "scores = cross_val[\"test_score\"]\n",
    "print(\"The mean cross-validation accuracy is: \"\n",
    "      f\"{scores.mean():.3f} +/- {scores.std():.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "nbreset": "https://github.com/INRIA/scikit-learn-mooc/raw/master/notebooks/03_categorical_pipeline_ex_01.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
